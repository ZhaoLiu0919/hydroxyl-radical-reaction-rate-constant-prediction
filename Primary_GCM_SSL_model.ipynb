{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general and data handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from collections import Counter\n",
    "from IPython.display import display\n",
    "import re\n",
    "import openpyxl as xl\n",
    "from scipy.spatial.distance import cdist\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required RDKit modules\n",
    "import rdkit as rd\n",
    "from rdkit.Chem.Fingerprints import FingerprintMols\n",
    "from rdkit import RDConfig\n",
    "from rdkit.Chem import PandasTools\n",
    "from rdkit import Chem\n",
    "\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit.Chem import rdFingerprintGenerator\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import MACCSkeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modeling\n",
    "import sklearn as sk\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics, model_selection\n",
    "from sklearn.model_selection import KFold, RepeatedKFold, GridSearchCV, cross_val_score, train_test_split, validation_curve\n",
    "\n",
    "import sklearn.linear_model as skl_lm\n",
    "from sklearn.metrics import classification_report, mean_squared_error, make_scorer, r2_score, mean_absolute_error\n",
    "from sklearn.preprocessing import PolynomialFeatures, MinMaxScaler, StandardScaler\n",
    "from rdkit.Chem.rdMolDescriptors import GetMorganFingerprintAsBitVect, GetMACCSKeysFingerprint\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphing & others\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBRegressor\n",
    "import xgboost as xgb\n",
    "import argparse\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return mae, rmse, r2\n",
    "\n",
    "def generate_predict_report(model, X, y):\n",
    "    y_pred = model.predict(X)\n",
    "    y_pred = y_pred.reshape(-1)  # To make sure the format is array([1, 2, 3..]).\n",
    "    MAE = mean_absolute_error(y, y_pred)\n",
    "    RMSE = np.sqrt(mean_squared_error(y, y_pred))\n",
    "    R2 = r2_score(y, y_pred)\n",
    "    print(f'MAE: {MAE}')\n",
    "    print(f'RMSE: {RMSE}')\n",
    "    print(f'R2: {R2}')\n",
    "\n",
    "    # Data scatter of predicted values\n",
    "    plt.figure();plt.clf()\n",
    "    plt.scatter(y, y_pred, marker='.', color='blue')\n",
    "    plt.xlabel(\"True value\")\n",
    "    plt.ylabel(\"Predicted value\")\n",
    "    plt.title(\"Prediction\")\n",
    "    plt.show()\n",
    "\n",
    "    dict_test = {'MAE': MAE, 'RMSE': RMSE, 'R2': R2}\n",
    "    return dict_test\n",
    "\n",
    "def generate_train_report(model, X_train, y_train):\n",
    "    print(\"-------------------------------------------------------------------------------------------\")\n",
    "    print(f\"Train report for model {model}:\")\n",
    "    return generate_predict_report(model, X_train, y_train)\n",
    "\n",
    "def generate_val_report(model, X_val, y_val):\n",
    "    print(\"-------------------------------------------------------------------------------------------\")\n",
    "    print(f\"Validation report for model {model}:\")\n",
    "    return generate_predict_report(model, X_val, y_val)\n",
    "    \n",
    "def generate_test_report(model, X_test, y_test):\n",
    "    print(\"-------------------------------------------------------------------------------------------\")\n",
    "    print(f\"Test report for model {model}:\")\n",
    "    return generate_predict_report(model, X_test, y_test)\n",
    "\n",
    "def evaluate_model(model, X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    train_metrics = calculate_metrics(y_train, y_train_pred)\n",
    "    val_metrics = calculate_metrics(y_val, y_val_pred)\n",
    "    test_metrics = calculate_metrics(y_test, y_test_pred)\n",
    "    \n",
    "    return train_metrics, val_metrics, test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def data_split(df_remain, X_test, y_test, X_total_remain, y_total_remain, random_state, n_clusters):\n",
    "    # Get the MACCS fingerprints for remaining set\n",
    "    fingerprints = [MACCSkeys.GenMACCSKeys(Chem.MolFromSmiles(smi)) for smi in df_remain['SMILES']]\n",
    "    \n",
    "    # Convert fingerprints to a numpy array\n",
    "    fp_matrix = np.array([list(fp) for fp in fingerprints])\n",
    "    \n",
    "    # Use KMeans clustering on the fingerprints\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=4).fit(fp_matrix)\n",
    "    df_remain['cluster'] = kmeans.labels_\n",
    "\n",
    "    X_train = []\n",
    "    X_val = []\n",
    "    y_train = []\n",
    "    y_val = []\n",
    "\n",
    "    # For each cluster, do a train-validation split for the remaining set\n",
    "    for i in range(n_clusters):\n",
    "        cluster_indices = df_remain[df_remain['cluster'] == i].index\n",
    "        X_train_cluster, X_val_cluster, y_train_cluster, y_val_cluster = train_test_split(X_total_remain[cluster_indices], y_total_remain[cluster_indices], test_size=0.1, random_state=random_state)\n",
    "\n",
    "        X_train.extend(X_train_cluster)\n",
    "        X_val.extend(X_val_cluster)\n",
    "        y_train.extend(y_train_cluster)\n",
    "        y_val.extend(y_val_cluster)\n",
    "        \n",
    "    return np.array(X_train), np.array(X_val), X_test, np.array(y_train), np.array(y_val), y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='chemical')\n",
    "parser.add_argument('-split', type=str, default=\"similar\", help='similar or dissimilar data set')\n",
    "parser.add_argument('-subset', type=float, default=0.1, help='subset of weak data')\n",
    "parser.add_argument('-iteration', type=int, default=10, help='number of iteration')\n",
    "parser.add_argument('-threshold', type=float, default=0.9, help='similarity threshold')\n",
    "parser.add_argument('-measure', type=str, default=\"maccs\", help='similarity measure')\n",
    "parser.add_argument('-seed', type=float, default=0.0, help='random seed for data split')\n",
    "\n",
    "args = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.split == \"similar\":\n",
    "    df_remain = pd.read_excel('./similar test set.xlsx', sheet_name='remaining_set', engine='openpyxl')\n",
    "    df_test = pd.read_excel('./similar test set.xlsx', sheet_name='test_set', engine='openpyxl')\n",
    "    best_params = {'colsample_bylevel': 0.5362386927724025, 'colsample_bynode': 0.7846605864264999, 'colsample_bytree': 0.5869205526328731,\n",
    "                   'gamma': 0.120232287455155, 'learning_rate': 0.04247055522398333, 'max_delta_step': 1, 'max_depth': 49,\n",
    "                   'min_child_weight': 1.407905723403665, 'n_estimators': 1247, 'reg_alpha': 0.4174734818527416,\n",
    "                   'reg_lambda': 0.9800779693705134, 'scale_pos_weight': 4.374540085845599, 'subsample': 0.9287718676241973,\n",
    "                   'booster': 'gbtree'}\n",
    "    cluster_num = 70\n",
    "elif args.split == \"dissimilar\":\n",
    "    df_remain = pd.read_excel('/home/drought/chemical/GenerateSimilarity/FinalVersion/data/remaining_set.xlsx',engine='openpyxl')\n",
    "    df_test = pd.read_excel('/home/drought/chemical/GenerateSimilarity/FinalVersion/data/test_set.xlsx',engine='openpyxl')\n",
    "    best_params = {'colsample_bylevel': 0.6889841308028768, 'colsample_bynode': 0.6415107155640306, 'colsample_bytree': 0.6224045119598769,\n",
    "                   'gamma': 0.17462902013639597, 'learning_rate': 0.04979875790770406, 'max_delta_step': 1, 'max_depth': 46,\n",
    "                   'min_child_weight': 1.9095319307329182, 'n_estimators': 1119, 'reg_alpha': 0.11535043067842797,\n",
    "                   'reg_lambda': 1.0902914563546875, 'scale_pos_weight': 1.824559842279296, 'subsample': 0.9872630630104621,\n",
    "                   'booster': 'gbtree'}\n",
    "    cluster_num = 85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_remain['mol'] = [AllChem.MolFromSmiles(smiles) for smiles in df_remain['SMILES']]\n",
    "df_remain_fp = [GetMACCSKeysFingerprint(mol) for mol in df_remain['mol']]\n",
    "## Split FP to multiple columns so that they can be easily combined with others\n",
    "fp_remain = pd.DataFrame(np.array(df_remain_fp))\n",
    "## Combine with pH and T\n",
    "df_remain_new = pd.concat([fp_remain, df_remain['pH'], df_remain['T']], axis=1)\n",
    "display(df_remain_new)\n",
    "X_total_remain = np.array(df_remain_new)\n",
    "y_total_remain = np.array(df_remain['Log k'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the X_train_fp finger print\n",
    "if args.measure == 'maccs':\n",
    "    X_train_fp = copy.deepcopy(df_remain_fp)\n",
    "elif args.measure == 'morg':\n",
    "    X_train_fp = [GetMorganFingerprintAsBitVect(AllChem.MolFromSmiles(m),2, nBits = 2048,\n",
    "                                            useChirality=False) for m in df_remain['SMILES'].values.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['mol'] = [AllChem.MolFromSmiles(smiles) for smiles in df_test['SMILES']]\n",
    "df_test_fp = [GetMACCSKeysFingerprint(mol) for mol in df_test['mol']]\n",
    "## Split FP to multiple columns so that they can be easily combined with others\n",
    "fp_test = pd.DataFrame(np.array(df_test_fp))\n",
    "## Combine with pH and T\n",
    "df_test_new = pd.concat([fp_test, df_test['pH'], df_test['T']], axis=1)\n",
    "display(df_test_new)\n",
    "X_test = np.array(df_test_new)\n",
    "y_test = np.array(df_test['Log k'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data files\n",
    "df_1_all = pd.read_excel('./GCM prediction 2.xlsx', sheet_name='0.5-0.4', engine='openpyxl')\n",
    "df_1 = df_1_all.sample(n=400, random_state=0)\n",
    "df_1['mol'] = [AllChem.MolFromSmiles(smiles) for smiles in df_1['SMILES']]\n",
    "df_1['fp'] = [MACCSkeys.GenMACCSKeys(mol) for mol in df_1['mol']]\n",
    "df_fp_1 = [MACCSkeys.GenMACCSKeys(mol) for mol in df_1['mol']]\n",
    "\n",
    "# Convert each fingerprint to a numpy array, then stack them vertically\n",
    "fp_1_array = np.vstack([np.array(fp) for fp in df_fp_1])\n",
    "fp_1 = pd.DataFrame(fp_1_array)\n",
    "\n",
    "# Combine with pH and T\n",
    "df_new_1 = pd.concat([fp_1, df_1['pH'].reset_index(drop=True), df_1['T'].reset_index(drop=True)], axis=1)\n",
    "display(df_new_1)\n",
    "print(df_new_1.shape)\n",
    "X_total_1 = np.array(df_new_1)\n",
    "y_total_1 = np.array(df_1['Log k'])\n",
    "display(y_total_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target = pd.read_csv('./DSSTox (100%).csv')\n",
    "df_target = df_target.sample(frac=args.subset, random_state=1, replace=True)\n",
    "df_target['mol'] = [AllChem.MolFromSmiles(smiles) for smiles in df_target['SMILES']]\n",
    "df_target_fp = [GetMACCSKeysFingerprint(mol) for mol in df_target['mol']]\n",
    "## Split FP to multiple columns so that they can be easily combined with others\n",
    "df_target_new = pd.DataFrame(np.array(df_target_fp))\n",
    "## Combine with pH and T\n",
    "df_target_new['pH'] = [7. for _ in df_target_new[0]]  # ph default to 7\n",
    "df_target_new['T'] = [25. for _ in df_target_new[0]] # T default to 25\n",
    "X_target = np.array(df_target_new)\n",
    "display(df_target_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.measure == 'maccs':\n",
    "    X_target_fp = copy.deepcopy(df_target_fp)\n",
    "elif args.measure == 'morg':\n",
    "    X_target_fp = [GetMorganFingerprintAsBitVect(AllChem.MolFromSmiles(m),2, nBits = 2048,\n",
    "                                            useChirality=False) for m in df_target['SMILES'].values.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = data_split(df_remain, X_test, y_test, X_total_remain, y_total_remain, random_state=int(args.seed), n_clusters=cluster_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_iterative_pseudo_labeling(hyperparameter, X_train, y_train, X_test, y_test, X_val, y_val, X_target,\n",
    "                                  X_train_fp, X_target_fp, X_train_gcm, y_train_gcm,\n",
    "                                  num_iteration=10, simi_threshold=0.9):\n",
    "\n",
    "    X_target_selected = X_train[[False] * len(X_train)]\n",
    "    y_target_selected = y_train[[False] * len(y_train)]\n",
    "\n",
    "    result_summary = pd.DataFrame(columns=['Qualified pseudo labels', 'MAE_test', 'RMSE_test', 'R2_test'])\n",
    "    best_MAE_test, best_RMSE_test, best_R2_test = float('inf'), float('inf'), float('-inf')\n",
    "    X_target_copy = copy.deepcopy(X_target)\n",
    "    X_target_fp_copy = copy.deepcopy(X_target_fp)\n",
    "    X_train_fp_copy = copy.deepcopy(X_train_fp)\n",
    "\n",
    "\n",
    "    for iteration in range(num_iteration):\n",
    "        print(y_train.shape, y_train_gcm.shape, y_target_selected.shape)\n",
    "        X_concat = np.concatenate([X_train, X_train_gcm, X_target_selected], axis=0)\n",
    "        y_concat = np.concatenate([y_train, y_train_gcm, y_target_selected], axis=0)\n",
    "        cur_model = XGBRegressor(**hyperparameter)\n",
    "        cur_model.fit(X_concat, y_concat, eval_set=[(X_val, y_val)], verbose=False)\n",
    "        target_preds = cur_model.predict(X_target_copy)\n",
    "        y_test_preds = cur_model.predict(X_test)\n",
    "\n",
    "        MAE_test, RMSE_test, R2_test = calculate_metrics(y_test, y_test_preds)\n",
    "        print('Iter {} Avg test MAE: {:.4f}, RMSE: {:.4f}, R2: {:.4f}'.format(iteration+1, MAE_test, RMSE_test, R2_test))\n",
    "        \n",
    "        fp_similarity = []\n",
    "        for i in range(len(X_target_fp_copy)):\n",
    "            similarity = []\n",
    "            for j in range(len(X_train_fp_copy)):\n",
    "                temp = DataStructs.FingerprintSimilarity(X_target_fp_copy[i], X_train_fp_copy[j])\n",
    "                similarity.append(temp)\n",
    "            fp_similarity.append(max(similarity))\n",
    "        fp_similarity = np.array(fp_similarity)\n",
    "\n",
    "        # update target selected\n",
    "        X_target_selected = np.concatenate([X_target_selected, X_target_copy[fp_similarity > simi_threshold]], axis=0)\n",
    "        y_target_selected = np.concatenate([y_target_selected, target_preds[fp_similarity > simi_threshold]], axis=0)\n",
    "        \n",
    "        qualified_labels = len(y_target_selected)\n",
    "        print('Qualified pseudo labels:', qualified_labels)\n",
    "        # update target_fp and train_fp list\n",
    "        # filter -- np.array()\n",
    "        filter = fp_similarity > simi_threshold\n",
    "\n",
    "        X_train_fp_copy = [i for indx,i in enumerate(X_target_fp_copy) if filter[indx] == True]\n",
    "        X_target_fp_copy = [i for indx,i in enumerate(X_target_fp_copy) if filter[indx] == False]\n",
    "\n",
    "        # update target\n",
    "        X_target_copy = X_target_copy[fp_similarity <= simi_threshold]\n",
    "\n",
    "        if R2_test > best_R2_test:\n",
    "            best_MAE_test = MAE_test\n",
    "            best_RMSE_test = RMSE_test\n",
    "            best_R2_test = R2_test\n",
    "        \n",
    "        result = pd.DataFrame([[qualified_labels, MAE_test, RMSE_test, R2_test]], columns=result_summary.columns)\n",
    "        result_summary = pd.concat([result_summary, result], ignore_index=True)\n",
    "\n",
    "        \n",
    "        if len(X_target_fp_copy) == 0 or len(X_train_fp_copy) == 0:\n",
    "            best = pd.DataFrame([[0, best_MAE_test, best_RMSE_test, best_R2_test]], columns=result_summary.columns)\n",
    "            result_summary = pd.concat([result_summary, best], ignore_index=True)\n",
    "            return result_summary\n",
    "    \n",
    "    best = pd.DataFrame([[0, best_MAE_test, best_RMSE_test, best_R2_test]], columns=result_summary.columns)\n",
    "    result_summary = pd.concat([result_summary, best], ignore_index=True)\n",
    "    return result_summary\n",
    "\n",
    "print(\"start pseudo labelling\")\n",
    "result_summary_out = run_iterative_pseudo_labeling(best_params, X_train, y_train, X_test, y_test, X_val, y_val, X_target,\n",
    "                                                   X_train_fp, X_target_fp, X_train_gcm=X_total_1, y_train_gcm=y_total_1,\n",
    "                                                   num_iteration=args.iteration, simi_threshold=args.threshold)\n",
    "\n",
    "stored_path = f\"./{args.split}_{args.subset}_{args.iteration}_{args.threshold}_{args.measure}_{args.seed}_model.csv\"\n",
    "result_summary_out.to_csv(stored_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
